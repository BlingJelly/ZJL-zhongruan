6.24 星期三
1813077 马诗雨
今天学习内容主要是Hadoop的I/O和MapReduce应用开发。
Hadoop自带一套原子操作用于数据I/O操作。其中有一些技术比Hadoop本身更常用，如数据完整性和压缩，序列化框架和盘数据结构。检验数据是否损坏最常见的措施是：在数据第一次引入系统时计算校验和并在数据通过一个不可靠通道进行传输时再次计算校验和，这样就能发现数据是否被损坏。HDFS会对写入的所有数据计算校验和，并在读取数据时验证校验和。此外，了解了ChecksumFileSystem的相关用法，运行了实现自定义的Writable的代码，学习了MapReduce应用开发，了解了实用层面以及MapReduce的工作流。MapReduce编程流程，首先写map函数和reduce函数，使用单元测试确保函数的运行符合预期，然后写一个驱动程序来运行作业。
随着对hadoop的了解越来越深入，更深切地感受到hadoop是一个很强大的工具，但是对我而言，的确太难了，我只能继续努力了，加油。